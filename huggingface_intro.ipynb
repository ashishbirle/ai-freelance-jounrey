{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/O8oz4iVPRcrLjqfE8f5Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishbirle/ai-freelance-jounrey/blob/main/huggingface_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FJQNOGZOVqJg"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentiment analysis\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "print(classifier(\"AI is a vast field and tyring to learn all sub-set of it in just few months is too difficult.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IzMdd8OWI0b",
        "outputId": "d7549b5d-e1a7-4bbb-df22-04c0aa8d590b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'NEGATIVE', 'score': 0.9992578625679016}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "print(generator(\"Primary projects in NLP and LLM freelancing should include\", max_length=100, num_return_sequences=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBZ4_TErWrMC",
        "outputId": "907342fe-609b-46c6-f977-f2aac742a0e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'Primary projects in NLP and LLM freelancing should include (but not limited to):\\n\\nNLP team members working on a new project.\\n\\nThe NLP project owner\\n\\nNLP freelancers working with other NLP teams.\\n\\nA working partner who works closely with you and provides technical support.\\n\\nA team that will help you with the following:\\n\\nPlanning for your next project\\n\\nAn understanding of how it works.\\n\\nA background in N'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "print(classifier(\"Transformer can be a neural network or it can be a movie, depends on the context\", candidate_labels=[\"tech\", \"media\", \"finance\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2O_LnE8Yg_v",
        "outputId": "2a94e46d-fd9b-4075-8cc1-15347d233ee7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sequence': 'Transformer can be a neural network or it can be a movie, depends on the context', 'labels': ['media', 'tech', 'finance'], 'scores': [0.7611781358718872, 0.23626422882080078, 0.002557621104642749]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "print(ner(\"The new book Source Code from Bill Gates was first launched in the USA and then to remaining countries.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMZktOkKZlDh",
        "outputId": "db41ecd3-46e4-4994-b955-68ecca43e683"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity_group': 'MISC', 'score': np.float32(0.9903195), 'word': 'Source Code', 'start': 13, 'end': 24}, {'entity_group': 'PER', 'score': np.float32(0.9251322), 'word': 'Bill Gates', 'start': 30, 'end': 40}, {'entity_group': 'LOC', 'score': np.float32(0.99972636), 'word': 'USA', 'start': 67, 'end': 70}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "\n",
        "result = translator(\"Natural Language Processing is a fun way to start understanding the functions of LLMs.\")\n",
        "\n",
        "print(result[0]['translation_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im8eYln_aKoY",
        "outputId": "b98840fe-0580-4cee-80f2-8059d21eab8c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le traitement du langage naturel est une façon amusante de commencer à comprendre les fonctions des LLM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch-translate multiple sentences\n",
        "translator = pipeline(\"translation\", model=\"helsinki-NLP/opus-mt-en-hi\")\n",
        "sentences = [\"How are you?\", \"Where are you from?\", \"What languages do you speak?\"]\n",
        "result = translator(sentences)\n",
        "\n",
        "for r in result:\n",
        "  print(r['translation_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ouqZJAbc0IS",
        "outputId": "1cf5fa86-0b33-4915-8242-b5270e7c3161"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "आप कैसे हैं?\n",
            "तुम कहाँ से हो?\n",
            "आप क्या भाषा बोलते हैं?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "text = \"\"\"Natural language processing (NLP) is a subfield of artificial intelligence (AI) focused on enabling computers\n",
        "to understand and process human languages. It plays a central role in applications like machine translation, sentiment analysis,\n",
        "chatbots, and voice assistants. Modern NLP models leverage deep learning techniques to analyse large datasets and produce more\n",
        "accurate, context-aware outputs.\n",
        "\"\"\"\n",
        "\n",
        "summary = summarizer(text, max_length=50, min_length=25, do_sample=True)\n",
        "print(summary[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4eIpCGQeXBk",
        "outputId": "faf6ea03-f998-47b5-ddcc-a237bcaf8e16"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'summary_text': ' Natural language processing (NLP) is a subfield of artificial intelligence (AI) focused on enabling computers to understand and process human languages . It plays a central role in applications like machine translation, sentiment analysis,chatbots, and voice'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_aZ5iZVgZhS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}